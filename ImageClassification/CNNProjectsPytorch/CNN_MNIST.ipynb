{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqmmgeuFb86l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "#for dataset\n",
        "from torchvision import datasets\n",
        "#For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1,out_channels=8,kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(8, 32, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output\n",
        "class N_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(N_CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            #out_channels=16, 8\n",
        "            nn.Conv2d(in_channels=1,out_channels=8,kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(8, 32, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 14 * 14, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "o8IBKSLy-ZRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate = .01\n",
        "num_epochs = 10\n",
        "model = CNN()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "Adam_optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "SGD_optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "DAhP3zmlglHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
        ")\n",
        "\n",
        "#Load Data:\n",
        "train_data = datasets.MNIST(root = 'data', train = True, transform = transforms.ToTensor(),download = True)\n",
        "test_data = datasets.MNIST(root = 'data', train = False,transform = transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "metadata": {
        "id": "lcjJb9pzgy0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.data.size())\n",
        "# print(train_data.data.size())\n",
        "# print(train_data.data[0])\n",
        "# plt.imshow(train_data.data[0], cmap='gray')\n",
        "# plt.title('%i' % train_data.targets[0])\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P5kJ8mwhbxr",
        "outputId": "8fd96f95-8a78-46ec-c559-9e05577c8b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, cnn, train_loader, optimizer, loss_function):\n",
        "    cnn.train()\n",
        "    # Train the model\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            #print(images.shape, labels.shape)\n",
        "            images_grad = Variable(images)\n",
        "            labels_grad = Variable(labels)\n",
        "            output = cnn(images_grad)\n",
        "            loss = loss_func(output, labels_grad)\n",
        "\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "\n",
        "#train(num_epochs, model, train_loader,SGD_optimizer,loss_func )"
      ],
      "metadata": {
        "id": "LncC8m9uj2K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, model, train_loader,SGD_optimizer,loss_func )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "uVGXIq-D-Jmu",
        "outputId": "db4e3685-e6b4-4841-9bbb-cde015963d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-33dec9978640>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSGD_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-5710fb7e3bbf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, cnn, train_loader, optimizer, loss_function)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimages_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c0b9f0dc6ac1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# flatten the output of conv2 to (batch_size, 32 * 7 * 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,test_loader,batch_size):\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    count=0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        accuracies = []\n",
        "        for images, labels in test_loader:\n",
        "            output = model(images)\n",
        "            pred_num = torch.max(output, 1)[1].data.squeeze()\n",
        "            accuracy = (pred_num == labels).sum().item() / float(labels.size(0))\n",
        "            accuracies.append(accuracy)\n",
        "            count+=1\n",
        "        print('Test Accuracy of the model on the 10000 test images: %.2f' % np.mean(accuracies))\n",
        "        print(count)\n",
        "#test(model,test_loader,batch_size)\n"
      ],
      "metadata": {
        "id": "NovITMY6j7Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Base Example'''\n",
        "# image_tensor = torch.empty(train_data.data.shape[0],1,56, 56)\n",
        "# print(image_tensor.shape)\n",
        "# for i in range(train_data.data.shape[0]):\n",
        "#   zeros = torch.zeros((56,56))\n",
        "#   rand_x = randint(0, 28)\n",
        "#   rand_y = randint(0, 28)\n",
        "#   for x in range(28):\n",
        "#     for y in range(28):\n",
        "#       zeros[x + rand_x][y + rand_y] = train_data.data[0][x][y]\n",
        "#   #print(zeros.shape)\n",
        "#   image_tensor[i] = zeros\n",
        "#   #image_tensor = torch.cat((image_tensor, zeros), dim=0)\n",
        "#   #print(image_tensor.shape)\n",
        "\n",
        "# new_loader = torch.utils.data.DataLoader(image_tensor,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "'''test'''\n",
        "# print(torch.squeeze(image_tensor.data))\n",
        "# plt.imshow(torch.squeeze(image_tensor.data)[0], cmap='gray')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z73cYAg2UwhR",
        "outputId": "973076a8-05b0-421b-d4ba-cef53c9aee86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "torch.Size([60000, 1, 56, 56])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.data = images\n",
        "        self.targets = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.data[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        return image, target\n",
        "\n",
        "def new_data_Loaders(train_data,test_data):\n",
        "  exp2_train_images = torch.empty(train_data.data.shape[0],1,56, 56)\n",
        "  exp3_train_images = torch.empty(train_data.data.shape[0],1,56, 56)\n",
        "  exp2_test_images = torch.empty(test_data.data.shape[0],1,56, 56)\n",
        "  exp3_test_images = torch.empty(test_data.data.shape[0],1,56, 56)\n",
        "  print(exp2_train_images.shape)\n",
        "  #exp3_images = torch.empty(train_data.data.shape[0],1,56, 56)\n",
        "  for i in range(train_data.data.shape[0]):\n",
        "    exp2_zeros = torch.zeros((56,56))\n",
        "    exp3_zeros = torch.zeros((56,56))\n",
        "\n",
        "    exp2_rand_x = randint(0, 28)\n",
        "    exp2_rand_y = randint(0, 28)\n",
        "    exp3_rand_x = 0\n",
        "    exp3_rand_y = randint(0, 28)\n",
        "\n",
        "    for x in range(28):\n",
        "      for y in range(28):\n",
        "        exp2_zeros[x + exp2_rand_x][y + exp2_rand_y] = train_data.data[i][x][y]\n",
        "        exp3_zeros[x + exp3_rand_x][y + exp3_rand_y] = train_data.data[i][x][y]\n",
        "    exp2_train_images[i] = exp2_zeros\n",
        "    exp3_train_images[i] = exp3_zeros\n",
        "    # if i ==20:\n",
        "    #   break\n",
        "\n",
        "  exp2_train = NDataset(exp2_train_images.data, train_data.targets)\n",
        "  exp2_train_loader = torch.utils.data.DataLoader(exp2_train,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "  exp3_train = NDataset(exp3_train_images.data, train_data.targets)\n",
        "  exp3_train_loader = torch.utils.data.DataLoader(exp3_train,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "\n",
        "  for i in range(test_data.data.shape[0]):\n",
        "    exp2_zeros = torch.zeros((56,56))\n",
        "    exp3_zeros = torch.zeros((56,56))\n",
        "\n",
        "    exp2_rand_x = randint(0, 28)\n",
        "    exp2_rand_y = randint(0, 28)\n",
        "    exp3_rand_x = 28\n",
        "    exp3_rand_y = randint(0, 28)\n",
        "\n",
        "    for x in range(28):\n",
        "      for y in range(28):\n",
        "        exp2_zeros[x + exp2_rand_x][y + exp2_rand_y] = test_data.data[i][x][y]\n",
        "        exp3_zeros[x + exp3_rand_x][y + exp3_rand_y] = test_data.data[i][x][y]\n",
        "    exp2_test_images[i] = exp2_zeros\n",
        "    exp3_test_images[i] = exp3_zeros\n",
        "    # if i ==20:\n",
        "    #   break\n",
        "  exp2_test= NDataset(exp2_test_images.data, test_data.targets)\n",
        "  exp2_test_loader = torch.utils.data.DataLoader(exp2_test,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "  exp3_test = NDataset(exp3_test_images.data, test_data.targets)\n",
        "  exp3_test_loader = torch.utils.data.DataLoader(exp3_test,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "  return exp2_train_loader, exp3_train_loader, exp2_test_loader,exp3_test_loader\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "exp2_train_loader,exp3_train_loader,exp2_test_loader,exp3_test_loader = new_data_Loaders(train_data, test_data)\n",
        "for i, (images, labels) in enumerate(exp2_train_loader):\n",
        "            print(images.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFebv8lEppyz",
        "outputId": "a9235f02-1969-429f-e790-15e9e99b6971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 56, 56])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n",
            "torch.Size([200, 1, 56, 56]) torch.Size([200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate = .01\n",
        "num_epochs = 10\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "model_2 = N_CNN()\n",
        "model_3 = N_CNN()\n",
        "Adam_optimizer_2 = optim.Adam(model_2.parameters(), lr = learning_rate)\n",
        "SGD_optimizer_2 = optim.SGD(model_2.parameters(), lr = learning_rate)\n",
        "Adam_optimizer_3 = optim.Adam(model_3.parameters(), lr = learning_rate)\n",
        "SGD_optimizer_3 = optim.SGD(model_3.parameters(), lr = learning_rate)\n",
        "\n",
        "train(num_epochs, model_2, exp2_train_loader,SGD_optimizer_2,loss_func)\n",
        "train(num_epochs, model_3, exp3_train_loader,SGD_optimizer_3,loss_func)\n",
        "test(model_2,exp2_test_loader,batch_size)\n",
        "test(model_3,exp3_test_loader,batch_size)\n",
        "# flatten the output of conv2 to (batch_size, 32 * 7 * 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gajZZdsQsmGW",
        "outputId": "1246cc27-cd8d-4594-e959-6eea89a0869c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/300], Loss: 2.9960\n",
            "Epoch [1/10], Step [200/300], Loss: 1.2181\n",
            "Epoch [1/10], Step [300/300], Loss: 0.6756\n",
            "Epoch [2/10], Step [100/300], Loss: 0.4949\n",
            "Epoch [2/10], Step [200/300], Loss: 0.3184\n",
            "Epoch [2/10], Step [300/300], Loss: 0.4144\n",
            "Epoch [3/10], Step [100/300], Loss: 0.3936\n",
            "Epoch [3/10], Step [200/300], Loss: 0.3007\n",
            "Epoch [3/10], Step [300/300], Loss: 0.1685\n",
            "Epoch [4/10], Step [100/300], Loss: 0.3323\n",
            "Epoch [4/10], Step [200/300], Loss: 0.2283\n",
            "Epoch [4/10], Step [300/300], Loss: 0.1780\n",
            "Epoch [5/10], Step [100/300], Loss: 0.1120\n",
            "Epoch [5/10], Step [200/300], Loss: 0.1118\n",
            "Epoch [5/10], Step [300/300], Loss: 0.1269\n",
            "Epoch [6/10], Step [100/300], Loss: 0.3296\n",
            "Epoch [6/10], Step [200/300], Loss: 0.1123\n",
            "Epoch [6/10], Step [300/300], Loss: 0.0797\n",
            "Epoch [7/10], Step [100/300], Loss: 0.0918\n",
            "Epoch [7/10], Step [200/300], Loss: 0.1388\n",
            "Epoch [7/10], Step [300/300], Loss: 0.1328\n",
            "Epoch [8/10], Step [100/300], Loss: 0.0869\n",
            "Epoch [8/10], Step [200/300], Loss: 0.1047\n",
            "Epoch [8/10], Step [300/300], Loss: 0.2000\n",
            "Epoch [9/10], Step [100/300], Loss: 0.0920\n",
            "Epoch [9/10], Step [200/300], Loss: 0.1204\n",
            "Epoch [9/10], Step [300/300], Loss: 0.0767\n",
            "Epoch [10/10], Step [100/300], Loss: 0.0404\n",
            "Epoch [10/10], Step [200/300], Loss: 0.1747\n",
            "Epoch [10/10], Step [300/300], Loss: 0.0894\n",
            "Epoch [1/10], Step [100/300], Loss: 14.1583\n",
            "Epoch [1/10], Step [200/300], Loss: 13.4456\n",
            "Epoch [1/10], Step [300/300], Loss: 13.9002\n",
            "Epoch [2/10], Step [100/300], Loss: 14.0658\n",
            "Epoch [2/10], Step [200/300], Loss: 12.6396\n",
            "Epoch [2/10], Step [300/300], Loss: 13.0252\n",
            "Epoch [3/10], Step [100/300], Loss: 13.3802\n",
            "Epoch [3/10], Step [200/300], Loss: 13.7601\n",
            "Epoch [3/10], Step [300/300], Loss: 13.7752\n",
            "Epoch [4/10], Step [100/300], Loss: 12.2813\n",
            "Epoch [4/10], Step [200/300], Loss: 13.7227\n",
            "Epoch [4/10], Step [300/300], Loss: 14.6851\n",
            "Epoch [5/10], Step [100/300], Loss: 14.0492\n",
            "Epoch [5/10], Step [200/300], Loss: 14.2265\n",
            "Epoch [5/10], Step [300/300], Loss: 13.6517\n",
            "Epoch [6/10], Step [100/300], Loss: 13.3979\n",
            "Epoch [6/10], Step [200/300], Loss: 14.6676\n",
            "Epoch [6/10], Step [300/300], Loss: 14.2642\n",
            "Epoch [7/10], Step [100/300], Loss: 14.4429\n",
            "Epoch [7/10], Step [200/300], Loss: 13.2706\n",
            "Epoch [7/10], Step [300/300], Loss: 14.1720\n",
            "Epoch [8/10], Step [100/300], Loss: 13.7050\n",
            "Epoch [8/10], Step [200/300], Loss: 13.6839\n",
            "Epoch [8/10], Step [300/300], Loss: 14.2045\n",
            "Epoch [9/10], Step [100/300], Loss: 14.0511\n",
            "Epoch [9/10], Step [200/300], Loss: 14.0237\n",
            "Epoch [9/10], Step [300/300], Loss: 14.1361\n",
            "Epoch [10/10], Step [100/300], Loss: 14.8719\n",
            "Epoch [10/10], Step [200/300], Loss: 13.8785\n",
            "Epoch [10/10], Step [300/300], Loss: 14.0925\n",
            "Test Accuracy of the model on the 10000 test images: 0.95\n",
            "50\n",
            "Test Accuracy of the model on the 10000 test images: 0.09\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(torch.squeeze(exp2_images.data)[6], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "lhskzq3Zsua9",
        "outputId": "64f4edca-b42e-468c-bc42-b70e97eb5cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe43f7f4fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, model_3, exp3_train_loader,SGD_optimizer_3,loss_func)\n",
        "test(model_3,exp3_test_loader,batch_size)"
      ],
      "metadata": {
        "id": "3LfpGSV0izpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ae35fb-74b0-444b-bcc2-53cd310875f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/300], Loss: 2.2743\n",
            "Epoch [1/10], Step [200/300], Loss: 2.2199\n",
            "Epoch [1/10], Step [300/300], Loss: 1.0643\n",
            "Epoch [2/10], Step [100/300], Loss: 0.9754\n",
            "Epoch [2/10], Step [200/300], Loss: 0.8244\n",
            "Epoch [2/10], Step [300/300], Loss: 0.5515\n",
            "Epoch [3/10], Step [100/300], Loss: 0.5171\n",
            "Epoch [3/10], Step [200/300], Loss: 0.3466\n",
            "Epoch [3/10], Step [300/300], Loss: 0.2461\n",
            "Epoch [4/10], Step [100/300], Loss: 0.1696\n",
            "Epoch [4/10], Step [200/300], Loss: 0.1726\n",
            "Epoch [4/10], Step [300/300], Loss: 0.1802\n",
            "Epoch [5/10], Step [100/300], Loss: 0.1294\n",
            "Epoch [5/10], Step [200/300], Loss: 0.0729\n",
            "Epoch [5/10], Step [300/300], Loss: 0.2363\n",
            "Epoch [6/10], Step [100/300], Loss: 0.1470\n",
            "Epoch [6/10], Step [200/300], Loss: 0.1980\n",
            "Epoch [6/10], Step [300/300], Loss: 0.1848\n",
            "Epoch [7/10], Step [100/300], Loss: 0.1233\n",
            "Epoch [7/10], Step [200/300], Loss: 0.1965\n",
            "Epoch [7/10], Step [300/300], Loss: 0.1671\n",
            "Epoch [8/10], Step [100/300], Loss: 0.0663\n",
            "Epoch [8/10], Step [200/300], Loss: 0.1366\n",
            "Epoch [8/10], Step [300/300], Loss: 0.1323\n",
            "Epoch [9/10], Step [100/300], Loss: 0.0962\n",
            "Epoch [9/10], Step [200/300], Loss: 0.0525\n",
            "Epoch [9/10], Step [300/300], Loss: 0.0734\n",
            "Epoch [10/10], Step [100/300], Loss: 0.0539\n",
            "Epoch [10/10], Step [200/300], Loss: 0.0899\n",
            "Epoch [10/10], Step [300/300], Loss: 0.0757\n",
            "Test Accuracy of the model on the 10000 test images: 0.08\n",
            "50\n"
          ]
        }
      ]
    }
  ]
}