{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DqmmgeuFb86l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "o8IBKSLy-ZRd"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\" \n",
        "  Implements a Convolutional Neural Network for Classification\n",
        "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        #input image shape 28x28x1 and apply convolutional layer with same padding\n",
        "        nn.Conv2d(in_channels=3,out_channels=8,kernel_size=5,stride=1,padding=2),\n",
        "        #new shape 28x28x8\n",
        "        nn.ReLU(),\n",
        "        #new shape 14x14x8\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        # input shape 14x14x8\n",
        "        nn.Conv2d(8, 32, 5, 1, 2),\n",
        "        # new shape 14x14x32\n",
        "        nn.ReLU(),\n",
        "        # 7x7x32\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.out = nn.Linear(32 * 8 * 8, 10)\n",
        "  def forward(self, x):\n",
        "    #print(f\"The input shape is {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"The shape after the first conv layer {x.shape}\")\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"The shape after the second conv layer {x.shape}\")\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(f\"The shape after flatening {x.shape}\")\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "\n",
        "  def train_model(self, num_epochs, train_loader, lr):\n",
        "    self.train()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            #compute the forward pass\n",
        "            output = self(images)\n",
        "            #compute the loss\n",
        "            loss = loss_function(output, labels)\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "                \n",
        "  def test_model(self, test_loader):\n",
        "    self.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass to get output/logits\n",
        "          outputs = self(images)\n",
        "          \n",
        "          # Predictions are the maximum value locations in logits dimension\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          \n",
        "          # Collect the predictions and labels\n",
        "          predictions.extend(predicted.cpu().numpy())\n",
        "          labels_list.extend(labels.cpu().numpy())\n",
        "    correct = (np.array(predictions) == np.array(labels_list)).sum()\n",
        "    total = len(labels_list)\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy * 100:.2f}%') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DAhP3zmlglHc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "The size of the train data (50000, 32, 32, 3)\n",
            "The size of the test data (10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#normalization\n",
        "transform1 = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Adjusted for one channel\n",
        "])\n",
        "\n",
        "#Load Data:\n",
        "# train_data = datasets.MNIST(root = 'data', train = True, transform = transforms.ToTensor(),download = True)\n",
        "# test_data = datasets.MNIST(root = 'data', train = False,transform = transforms.ToTensor())\n",
        "\n",
        "train_data_norm = datasets.CIFAR10(root = 'data', train = True, transform = transform1,download = True)\n",
        "test_data_norm = datasets.CIFAR10(root = 'data', train = False,transform = transform1)\n",
        "\n",
        "# Define sizes for split\n",
        "num_train = len(train_data)\n",
        "num_val = int(0.2 * num_train)  # Let's use 20% of the training data for validation\n",
        "num_train = num_train - num_val\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_data, val_data = torch.utils.data.random_split(train_data, [num_train, num_val])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"The size of the train data\", train_data_norm.data.shape)\n",
        "print(\"The size of the test data\", test_data_norm.data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lcjJb9pzgy0X"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGxCAYAAADLfglZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxWElEQVR4nO3de2zc9Zn3/c+cPbbHkziJT4kJLiS0JSS9SyhJHg6BFi+umhsaVkvLig3aXVTKQYrSijagR3G72gSxIqK3smS1bR8WtEQgPQssujlmF5KUO80qoeEhy6mhBOIQO87BZ4/n+Hv+oLFqksD3Sux8bef9kkYiMxeXv7/DzOXxzHwmFARBIAAAPAj7XgAA4NzFEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACzqLXX39d3/72tzV16lQlk0nNmTNHf/d3f+d7WYA3Ud8LAM4VmzZt0q233qq/+Iu/0OOPP67Kykr94Q9/0MGDB30vDfAmRHYcMPY++eQTXXTRRfqrv/orPfLII76XA4wb/DkOOAt+9atfaWBgQD/5yU98LwUYVxhCwFmwbds2VVdX67333tPXvvY1RaNR1dTU6I477lBvb6/v5QHe8Oc44Cz48pe/rI8//lixWEyrV6/W4sWLtXPnTq1Zs0Zf//rX9Zvf/EahUMj3MoGzjjcmAGdBqVTS0NCQ1qxZo5/+9KeSpKVLlyoej2vlypX6z//8T33rW9/yvErg7OPPccBZMG3aNEnSn/3Zn424vqWlRZL0u9/97qyvCRgPGELAWTB//vyTXn/8r+HhMHdFnJs484Gz4KabbpIkvfjiiyOuf+GFFyRJixYtOutrAsYDXhMCzoLm5mYtW7ZMP//5z1UqlbRo0SLt2rVLP/vZz/Sd73xHV1xxhe8lAl7w7jjgLMlkMvrZz36mTZs2qb29XQ0NDfrLv/xLrVmzRolEwvfyAC8YQgAAb3hNCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4M24+7BqqVTSwYMHlUqlSBUGgAkoCAL19fWpoaHhCyOpxt0QOnjwoBobG30vAwBwhtra2jRr1qzPrRl3QyiVSkmSLv3G5YpG3ZbX09Pl3D8RLpnWMzXu/lneWVPLTb2nV7vXT0tXmHrHwzHn2kgiaeqtSMRU3tXd41ybL9g+Oz0lnXauDRfzpt7ZXNa5dmjIvVaSypK2hISiis61mcyAqXdVOuVeHLivQ5JyOfd9HjE+HEUM52FlRaWpd0W57b4cjZU51w5lc6beQcjwqknYtg9zOfe1FAL3v0wNZXP6v//XE8OP559nzIbQI488on/4h39Qe3u7Lr74Yj388MO68sorv/D/O/4nuGg06jyELCdjJGz7E1804v6gGI/ZHpwTMffdXxZ3HyqSFI+410cTtt6K2E6bjGHt4bBtCJUZ1h62PX4qJMMvLCVbc+vxLBpevi0VbcfHsg8V2F5GDsv9eEZk2yeW+33SeI4ny+Km+ljMvd76KsNYDqGIYS2WIXScy0sqY/LGhKeeekorV67U/fffr927d+vKK69US0uL9u/fPxY/DgAwQY3JEFq/fr3+5m/+Rn/7t3+rr3zlK3r44YfV2NiojRs3nlCbzWbV29s74gIAODeM+hDK5XJ644031NzcPOL65uZmbd++/YT6devWKZ1OD194UwIAnDtGfQgdOXJExWJRtbW1I66vra1VR0fHCfWrV69WT0/P8KWtrW20lwQAGKfG7I0Jn31BKgiCk75IlUgk+C4VADhHjfozoenTpysSiZzwrKezs/OEZ0cAgHPbqA+heDyuSy+9VJs3bx5x/ebNm7VkyZLR/nEAgAlsTP4ct2rVKt16661auHChFi9erH/+53/W/v37dccdd4zFjwMATFBjMoRuvvlmHT16VD//+c/V3t6uefPm6YUXXtDs2bOde7z33rsKfUHm0HHdR4449612/2CzJCk0zf1/mF40fPJcUihZ41w7UDpm6t1fdP+QYBCyfTBvcMj2ie/BjHuaQL5oS7Q4Yvi0XVnU9kHYQsF9LRHjhwStr4MODrmnIBRKtuMTGprmXBu2fR5b+az7sU9GbXfOfkPywLFiwdS7vNyWUBIyJJSEDB8klyQ5Pg5K0uCQLRWkkDckWkTdz9ls3n1/j9kbE+68807deeedY9UeADAJ8FUOAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAb8YsMeFMlUVDCocdI1kMCSizDTE8knR+bdq5tmZGtal30hAN4vJd7X8qkx1yrh3Ku0erSFJgXEs8mXQvLtiidYKS+9rT1eWm3oW8+1riMcM2SioWTeWKxA2RKTn3Yy9J+YL78Sw3rEOSohXu+6XM2LsQco8yCge2OKiCbOe4IT1KlRW287B/YNC5Nl+wxfa4PsRKUl9vj3NtLu9+gvNMCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAODN+M2OCxUVDrnlPaVS7psxd+ZU0zqmJSPOtbGSLbOr/1jOubZYsv2+kBksONeG46bWqppSaaqPGjLBunv6bL0NZ3B1ypbZ1dfrnk2WG3KvlaTMkC3jKzBkmVVWuGcSSlI+l3GuDRdtDxmxhPuxLxZt+yRqCGzLZm294zHbnSJccr+/Zfu7TL1VdM8wTLg/XEmSCiX3TL2eAfecxlzBvS/PhAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3ozb2J4piYgiYbcZmTREg6QrkqZ1zKiKOdcWS0VTb0t1JGrM43Dcd5KULRnjUixZOZKigXuERzHrHiEjSUHEfTs7O7tNvYt59yPUNzho6j1YdI9skqTKZJV7cdZ2HkZkiFgJuUfISFIkUeZcmxmwxV6Vx9z3STSwrXtoyHZ8Mnn32J6SbGvp7nffL92DtvtyvyHeayjvfl8rFIntAQBMAAwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA34zY7bnq6TFHHXLBUzD1XrazMlsEWjrjnPCWTtly6fME946ukkKl3ELhnX+UKtiyrYs6WT1UK3OsDY6ZaEI071/blBky9i0X3c2XQkJUl2bK1JKlvwH0ffnLMtp2xsPtaqvpt52G+44hzbabHlr933vQLnWtramaZeodSPab6bNdR59r+ftvx6elzz4470mPLXvyozX07ixH3cVEyZPXxTAgA4M2oD6HW1laFQqERl7q6utH+MQCASWBM/hx38cUX6z/+4z+G/x2JGL+GAABwThiTIRSNRnn2AwD4QmPymtDevXvV0NCgpqYmfe9739OHH354ytpsNqve3t4RFwDAuWHUh9Dll1+uxx9/XC+//LJ++ctfqqOjQ0uWLNHRoyd/98i6deuUTqeHL42NjaO9JADAODXqQ6ilpUU33XSTLrnkEn3rW9/S888/L0l67LHHTlq/evVq9fT0DF/a2tpGe0kAgHFqzD8nVFFRoUsuuUR79+496e2JREKJRGKslwEAGIfG/HNC2WxW7777rurr68f6RwEAJphRH0I//vGPtXXrVu3bt0//9V//pT//8z9Xb2+vVqxYMdo/CgAwwY36n+MOHDig73//+zpy5IhmzJihRYsWaceOHZo9e7apT930csWjbp8vqooXnPtWlrvHvEhSyBA5I9nib0KBe1xKNmOLNAkbYn6mpdKm3hUVZab63h736JZ0VZWpd9+Q+/H5+BP3dUhSf9b9821xWwqPZpbb7nrRmHscy0dHu029s4H7dsZCtnM8XZVyrl3y1YWm3r3t7rFXwaBx3dNjpvrsoPvx7O+3/e6fiLmvpbHOfX9LUk1NrXPtoV73+KBCsaT9/33AqXbUh9CTTz452i0BAJMU2XEAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG/G/KscTtfUyqQSMbdMq2iu27lvImbb5PJEuXNtNmPJmZPyJffMuylTppp6B4F7VlauaPtdJJ93z5CSpPLKSufag4ezpt5/+LjHufZwn/v+lqRBQ/nspHv+miTdeOXXTPWz6t334f/7xqm/yfhkfvtBh3NtoZQz9Y6G3c/Dvu7Dpt6D/e7nSiply4JT0T17UZLKytz7x8ts50p5yL13oWg7x89rbHCuTR3rc67N5Yva5pgdxzMhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA34za2Z8bUapXF3ZaXOeYeIxMO2Ta5f9A9iieTs0VmREPu8R2D+aKpt+W3i0zeFsUyZWqVqT5XdI9u+fDAQVPvY73u+yWIxk29IxH3vVhVZjs+NVH3CBRJKjvmHlEzp6rO1Lu92n07D3V3mnpnB93Prd2//72pd7hQcq7NV9jOWaVrbfVh98eVdNo9CkySUiX3+89QzhYdFuR6nWvPn1FhWIf7YyHPhAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADejNvsuCnTpiuZiDnVTq1MOvcNh916Htfd2+Vcmx/oN/UOF93zxkpyz8mSpCDmfmgrK8tMvfOy1b/7oXsm2EB2wNS7rCzhXuuYRXhcssI942tqxJYb+MYHh0z1hZz72rNpW3bcjKnuxzMkWwZbvuCe6ziYy5h6Dwy6Z6rlCrbjEzLmKSrkXhoLG4olBWH3jMlY1HaOF7LumYSBIQPSUsszIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA34zY7TuGo5JjzForZ8uAsEmXuvctVYeodNfwOEA7bfl/IG7LmEsm0qfeRjj5T/eAR9/y9L1Xbcumy7tFkKjNkwUnSRRfMdK4NWxYiqRCxnbO9hgzDaKTH1DsVdz9vp029wNT7gjnnOdfu27/T1Pu933/iXBuPumekSVIQ2HIgCwX3h9JwNG7qHYu7nyulki1jsmQIvQuF3B+DLLU8EwIAeGMeQtu2bdOyZcvU0NCgUCikZ599dsTtQRCotbVVDQ0NSiaTWrp0qd5+++3RWi8AYBIxD6GBgQEtWLBAGzZsOOntDz74oNavX68NGzZo586dqqur03XXXae+PtufcAAAk5/5NaGWlha1tLSc9LYgCPTwww/r/vvv1/LlyyVJjz32mGpra7Vp0yb94Ac/OLPVAgAmlVF9TWjfvn3q6OhQc3Pz8HWJREJXX321tm/fftL/J5vNqre3d8QFAHBuGNUh1NHRIUmqra0dcX1tbe3wbZ+1bt06pdPp4UtjY+NoLgkAMI6NybvjQqGRb/sLguCE645bvXq1enp6hi9tbW1jsSQAwDg0qp8Tqqv79LvtOzo6VF9fP3x9Z2fnCc+OjkskEkokEqO5DADABDGqz4SamppUV1enzZs3D1+Xy+W0detWLVmyZDR/FABgEjA/E+rv79cHH3ww/O99+/bpzTffVHV1tc477zytXLlSa9eu1Zw5czRnzhytXbtW5eXluuWWW0Z14QCAic88hHbt2qVrrrlm+N+rVq2SJK1YsUL/8i//onvvvVeZTEZ33nmnurq6dPnll+uVV15RKpUy/ZyhoYIUuEVKhPIZQ+eCaR0DA+7v1svlbU8sC2H3iJr+QdvnrHoN9TMbbadBULCtZfZ092iQCxpscTaDQ+69Z85dYOodD9yjeLp68qbeySnTTPU6GnEubayr/+KiP9E9MOBc+6UvzzH1rprqHpVUNfUrpt5dh93Pw64eW5RRzBBlJEnhwP0lhXypaOptSeIp5m2Pb2H3u4+CIBiTWvMQWrp06ef+gFAopNbWVrW2tlpbAwDOMWTHAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8GdWvchhNxVBRxZDbjAyK7nlJlkwjSUqWJZ1rK1PuOVmSdPCwe+bdvgOHTb2jMfftjB86aOo9dMi2ljk17nlw31xqyyb7wyfHnGtTM2eYek+fVudc23n4kKn3lCnGbLKS+z6Mh91z5iSp8/AnzrXRsm5T78Pd7c61n7T3m3rHYu73tylVhgA2SZmM7XEiiLr/Ph+yBLZJKhmy5sKn+N62U6/Ffd1F2y5xxjMhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA34za2J52uULIs7lRbiLrH9vT3D5nWEeTdIzN6+npMvT/e7x710t9vizRJlrn/ftG+r9fUu9bxuBw3c+Zs59opDU2m3rE+QxxLmXv0jSTNWvAN99Yd7tE3kpQs2KKPinI/bwcGbOd4fbl7nFGuaIu/CVVUOtfOqmgw9U5NcY9V6jvaYerdeeioqT4fcj+3hnJZU2+F3fNyKhJlpta5jPvjSizuvo1FuccH8UwIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4M24zY7r7zmmwpBbVlE01+fcNxYyzt2Ie2k0YiiWNNjvnjU3NVVh6j2lwj1DKtNly46raZhmqp85/2rn2v8+kDP1/v0H7vVL6qtNvbu73XvXXrDA1DusQVN9LuueNTclsOW79Xa656Qlc3lT7/pq933eXUyYesfmT3WuzXS3m3r/nxeeM9UfaHM/PhFDBtun3HPYMu4xc5KkvOF5SDjvfuyH8u55njwTAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4M25je8IhKeKYVlHM9Dv3DQwRGJIUlnv8RDFki+3pMiSg9Pba8jiCrHvkTH3aFgl02TXXmOpnXbTIufbpR/8fU++6ikrn2kguY+r9yYd/cF/Hl75q6l027UJTfUXgHk01eKzT1DtZco+/yWVscUNH+tzrp8xoMvWeVne+c22mv8rUO2wrVzE+5FwbCtseg/J59/tyqFA09Q4F7vWFgvu4yBfdH694JgQA8IYhBADwxjyEtm3bpmXLlqmhoUGhUEjPPvvsiNtvu+02hUKhEZdFi9z/HAMAOHeYh9DAwIAWLFigDRs2nLLm+uuvV3t7+/DlhRdeOKNFAgAmJ/MbE1paWtTS0vK5NYlEQnV1dae9KADAuWFMXhPasmWLampqNHfuXN1+++3q7Dz1u3Wy2ax6e3tHXAAA54ZRH0ItLS164okn9Oqrr+qhhx7Szp07de211yqbzZ60ft26dUqn08OXxsbG0V4SAGCcGvXPCd18883D/z1v3jwtXLhQs2fP1vPPP6/ly5efUL969WqtWrVq+N+9vb0MIgA4R4z5h1Xr6+s1e/Zs7d2796S3JxIJJRK275YHAEwOY/45oaNHj6qtrU319fVj/aMAABOM+ZlQf3+/Pvjgg+F/79u3T2+++aaqq6tVXV2t1tZW3XTTTaqvr9dHH32k++67T9OnT9d3v/vdUV04AGDiMw+hXbt26Zo/yQ47/nrOihUrtHHjRu3Zs0ePP/64uru7VV9fr2uuuUZPPfWUUqmU6eeEgk8vLop59xC2UNj25C9qKA8yhjA4SaGSe231tHJT77py98y7ry+ca+r9lSW2Dx93dbpn+yUKPabeX5o1y7m2ZNnhkupqZjjXFobc97ckDXa754FJUq7g3j+fsd2ti3LP3/vDJwdMvff89y7n2iWLbPtkWt0059rePlueXsx2d9P0893zF0vGx6BizpDvZsiMlKSew93Otdk+952Szbuv2TyEli5dqiA49XR4+eWXrS0BAOcosuMAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN6M+Vc5nK5SoahSxG1GZrLumWDxCvecLEmKRmPOtZGwLbfpwrqpzrVlSdvvC+fPdv9OpgVXXPPFRX+i/qL5pvo3f/uoc+15je77RJLqLr7EuTY+4wJT72h52rl2cMg9H0+SMr19pvpDB9uca7sO2fLdivlB59pkqszUe/p09/tP28Hdpt619TOdawuDtuMTZE7+JZynEhrocq4tBhnbWlxDNCUlE+77W5Lide71vYmQc+1Qzr2WZ0IAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG/GbWxPLBJVLOK2vK4+99iR4pB7nIQkJcuTzrWRsHu8hiTVTCt3rm1r7zb1vuDr1zvXzrrEvfZTtmidfN+Ac2065R6VI0kz5n7NuXYgWm3q/fbunc612Yz7NkpSb2+3qf7IJ/udayNFW3xUWZn7w8DMJveoHEmaP/dC59pCpMLUOxaZ4l4bz5t6R4eGTPWDH3/iXFsqFE29C4anCv2RiKl3+TT3fV7bMM25NjPkvo08EwIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4M26z43JDWYVLbvlD5Qn3zQiV2bKVYuGCc21QdK+VpGSl+1r+583/09R7Scs3nWurpteaeh/68F1TfcSwD7v7eky9D3/0vnPtwT5bZteWZ591rq1Mxky9h7L9pvq6WvdMvaqULYNt34E259qc4VhKUnXD+c61cy+51NRbxYRz6bHuA6bWg8aMya6M+34JBbaH3aFMybm2P7DlVwb97hl5X5ni3nfIEF/IMyEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDfjNranFORUChzjKhzjfSQpVHCPwJCkQpB37x2yRWaUJaqca792qS3SJBFzj5F5583dpt5dB/9gqs9m3aNB+rqOmXq3ffCOc21/kDT1jhXd110ZtcVBVZXZonVmTHWP7Wk/1GHqXci7n+ODfba4obZ9+w3Vb5t69/f3OdeWRW33zUKixlR/tOB+X04my0y9y1Pu520y6h5lJEl9g73OtYWSezRRwfCYzDMhAIA3DCEAgDemIbRu3TpddtllSqVSqqmp0Y033qj33x+ZYhwEgVpbW9XQ0KBkMqmlS5fq7bdtT7MBAOcG0xDaunWr7rrrLu3YsUObN29WoVBQc3OzBgYGhmsefPBBrV+/Xhs2bNDOnTtVV1en6667Tn197n+/BQCcG0xvTHjppZdG/PvRRx9VTU2N3njjDV111VUKgkAPP/yw7r//fi1fvlyS9Nhjj6m2tlabNm3SD37wgxN6ZrNZZbPZ4X/39rq/UAYAmNjO6DWhnp5Pv4CsurpakrRv3z51dHSoubl5uCaRSOjqq6/W9u3bT9pj3bp1SqfTw5fGxsYzWRIAYAI57SEUBIFWrVqlK664QvPmzZMkdXR8+tbQ2tqR39RZW1s7fNtnrV69Wj09PcOXtjb3b3kEAExsp/05obvvvltvvfWWXn/99RNuC4VGfjVuEAQnXHdcIpFQImF7bzsAYHI4rWdC99xzj5577jm99tprmjVr1vD1dXV1knTCs57Ozs4Tnh0BAGAaQkEQ6O6779bTTz+tV199VU1NTSNub2pqUl1dnTZv3jx8XS6X09atW7VkyZLRWTEAYNIw/Tnurrvu0qZNm/Tv//7vSqVSw8940um0ksmkQqGQVq5cqbVr12rOnDmaM2eO1q5dq/Lyct1yyy1jsgEAgInLNIQ2btwoSVq6dOmI6x999FHddtttkqR7771XmUxGd955p7q6unT55ZfrlVdeUSqVMi6t9MeLQ2Uh59w1Gis3raJYcM9Aysk9W0mSatNTnWtffu5/m3pX17p/QLim3vaOxNxgj6k+FnN/za+ywj2DS5KiYffMtgpDnp4k1dVMc67N9HWZeicjttdBjx4+4lybz7mfs5KUKnPPJsv127Lj9u7e5Vzb/t7vTb2zhYx7ccyW7Vc0nFeSVDHLkAVY4f54JUnhhHuGYZkh302Spsr92H/l4qYvLvqjwUxe0v/nVGsaQkHwxSGAoVBIra2tam1ttbQGAJyDyI4DAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4c9pf5TDWSqWQSqWTf/3DZ8Wj7hEbZVG3KKBhYbc1SFIQMUR3SCrl8s61R46c/PuYTqX/sHt9Mm/7NtuSbJEm1VPd42+mNMww9S4Us19c9EefHLTtw0BfnBByXDhsuyvlCrZ4lUjIPXKooswWTVUw3CUilmJJCrnvw2LOFgcVdnx8kKTeQVusUi5hiASSlGpwPw8Hkt2m3n0l95ifoQHb84ppVV9yrp1uiLEaGHBfM8+EAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN6M2+y4cCihcMhteWWJpHPfQLbMroqkew5XRWq6qfdgfsi5dloqbuodNWxnrueQqXcpbFvLYMw9b6y2tsm2lpx7RtVF82eZem9/7T+da3PBoKl3LOSeeyZJmX73/lWpKlPveNT9YSASsmXH9Q+5n+P72m35bt3d7ud4NjRg6j1jru3385lT3B+DcoHt/tN1xP3Yx4fcMwYlqWKmex5cZrDoXptxr+WZEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAm3Eb2xOLhhSPus3IwWzWuW+krMK0jlIk4Vw7mM+YekdigXNtIu4eCyJJsZj7dsbL06be6SrbPuw47B4LNDjTFq1T03ihc+0nnUdMvS++7P9yru0/fNDU+8Pfv22qH+jvdq6NRmznYTrtHvMTki22p/0T9/2y/+MeU+9wwv08rKp1j9+SpBnVtuijkCGeKHTMdv+Z2uX+MD2zptrUe9YU9/vbB+90ONdmhvLOtTwTAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHgzbrPjaqaFVV7mNiPzR486980UbdlXAwPutUG4aOodjbrv/qqqaabe8VjMuTYz0GvqnYwZT5uce/2u7dtNrb90kXsu3YED7tlXkhQOh5xryxPu+1uSIoZMQklKJt3zxgb6bdlxmYx7faGQM/WuTLpv55L/MdfUuyzlnu9WiBRMvYv5QVN9ps09Oy7cV2bqXVOecq79H3MvtvWeUutc+0b7PufaoZz7/uaZEADAG9MQWrdunS677DKlUinV1NToxhtv1Pvvvz+i5rbbblMoFBpxWbRo0aguGgAwOZiG0NatW3XXXXdpx44d2rx5swqFgpqbmzXwmb9ZXX/99Wpvbx++vPDCC6O6aADA5GD64/5LL7004t+PPvqoampq9MYbb+iqq64avj6RSKiurm50VggAmLTO6DWhnp5Pv4SqunrkFylt2bJFNTU1mjt3rm6//XZ1dnaeskc2m1Vvb++ICwDg3HDaQygIAq1atUpXXHGF5s2bN3x9S0uLnnjiCb366qt66KGHtHPnTl177bXKnuLbT9etW6d0Oj18aWxsPN0lAQAmmNN+i/bdd9+tt956S6+//vqI62+++ebh/543b54WLlyo2bNn6/nnn9fy5ctP6LN69WqtWrVq+N+9vb0MIgA4R5zWELrnnnv03HPPadu2bZo16/O/o7y+vl6zZ8/W3r17T3p7IpFQImH7zAQAYHIwDaEgCHTPPffomWee0ZYtW9TU1PSF/8/Ro0fV1tam+vr6014kAGByMr0mdNddd+lf//VftWnTJqVSKXV0dKijo2P4E9f9/f368Y9/rN/+9rf66KOPtGXLFi1btkzTp0/Xd7/73THZAADAxGV6JrRx40ZJ0tKlS0dc/+ijj+q2225TJBLRnj179Pjjj6u7u1v19fW65ppr9NRTTymVco+eAACcG8x/jvs8yWRSL7/88hkt6LhZs+KqTLrlcaVD7llMH7TZMqEOHf78bf5TuaLtta3KSvfdPzDYY+pdLPU710aMb5I8dtg9q0+S+vrdc6SG8rbtjATu9anKqabehzqOOdceGHDPDpOkUuCeSydJtTPcswNDpbypd1d3l3NtosJ2jk9Ju//yGY/YzsNszpDVGLVl+w1kbWvJ9bv3ryjZel/Y6P6Zy4Y6W8Zk2wH37MWjh90fO7N592NDdhwAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwJvT/j6hsVY1JabKcrcojIwhTmJqTcS2kIpy59Ijh07+xX2nMpTLOddG41Wm3obWKhkiNiQpX7RtZ0/GPRamImmLhRkadI/LyQwdMfXOGfZL0bgPg8B2Hvb3up/jVVVJU++qqrRzbSZji706ctT92FdWVph6h8Luv0OHCu7xW5IUj9r2YcI9OUzxuO3Yn3/h+c61mUHbdm7b9o5z7Vu/P/U3ZH9WoVhyruWZEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMCbcZsdFymLKlrmtryyqrhz3+pK29yNZtxz0mJJ97wkSertMuz+om3dybIa99Yx27qL2W5TfbzcfTtjUfdjKUmRiHu2XzawbWcu7x7AFwQhU++QLeJLQc49I6/oXipJikXdMholSXFbtl93l3t2XCaXN/VOT3HPU4wacuYkKWw8DwdVcK49dKTP1Lur371330CPqfd/bHnPufaQITawVHI/wXkmBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwZtzG9gz0RxUqOcaJRCqd+1ZW2DJNYkn3+ImKRJmpdzrtHiPT35sx9e7vPeReO1g09c4P2epT8WnOtWUxQ4SMpELWPVYpGrX9zhU3lMcSEVPvUMi2lvJK97tq2HivLhTdY2HiSVvzqinusUrHjtnibPoMMUxV1e7noCQNFtwjmyRp70dHnWvf29Nm6l1b7R5PVDvLfX9LksLu+3B6OuVcWyyV9HGX22Mtz4QAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3ozb7LiDbVK5YxRbtts9sy01wz0nS5LKknnn2rR7hJ0kqbrafff3Dwyaend3u9d3HY2bene5x2RJkiIl91y1UuCe1SdJxaIhx65ky7yz/IYWCodMvSNR210vU3RfTWA7xRUruZ/jhcFjpt7FjPt5WIzacgO7+91752yHXseMWY0ffeB+p+g+OmDqnRtwX3xdus7U+yuzZzrXWnZJvljS7z5yO1d4JgQA8MY0hDZu3Kj58+erqqpKVVVVWrx4sV588cXh24MgUGtrqxoaGpRMJrV06VK9/fbbo75oAMDkYBpCs2bN0gMPPKBdu3Zp165duvbaa3XDDTcMD5oHH3xQ69ev14YNG7Rz507V1dXpuuuuU1+fLaIdAHBuMA2hZcuW6dvf/rbmzp2ruXPn6u///u9VWVmpHTt2KAgCPfzww7r//vu1fPlyzZs3T4899pgGBwe1adOmsVo/AGACO+3XhIrFop588kkNDAxo8eLF2rdvnzo6OtTc3Dxck0gkdPXVV2v79u2n7JPNZtXb2zviAgA4N5iH0J49e1RZWalEIqE77rhDzzzzjL761a+qo6NDklRbWzuivra2dvi2k1m3bp3S6fTwpbGx0bokAMAEZR5CF110kd58803t2LFDP/zhD7VixQq98847w7eHQiPfqhoEwQnX/anVq1erp6dn+NLWZvvqWwDAxGX+nFA8HteFF14oSVq4cKF27typX/ziF/rJT34iSero6FB9ff1wfWdn5wnPjv5UIpFQIpGwLgMAMAmc8eeEgiBQNptVU1OT6urqtHnz5uHbcrmctm7dqiVLlpzpjwEATEKmZ0L33XefWlpa1NjYqL6+Pj355JPasmWLXnrpJYVCIa1cuVJr167VnDlzNGfOHK1du1bl5eW65ZZbxmr9AIAJzDSEDh06pFtvvVXt7e1Kp9OaP3++XnrpJV133XWSpHvvvVeZTEZ33nmnurq6dPnll+uVV15RKpUyL6wYm6ZizO3PdPn4Que+2VLWtI5w4YhzbVnaFt0yZYZ73NDUsC2LpXqw5FzbfSxp6t19xD2GR5IyA+6nWbFgixBS4P5kvlRw3yeSNJQZcq6Nx23rjkRt+7BvyH3tmX73dUtSLMg516bCtvtyKez+btd83vbqQKLCPeKpzPGx5Lgpcfd9Iklf0hTn2ksWVJh6XzR/gXPt+X98qcTVNxa5Rx8dONjvXJvNFaTffeRUazrqv/71rz/39lAopNbWVrW2tlraAgDOUWTHAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvDGnaI+1IPg0imNwyD02I2OoDcXypvWUSu5xOeFBW2xPdMCwlnDR1Hsg4x7zMpCx7ZNBQ4SMJGWG3ONVDLv7j8Ywtifrvl+Kge3YR4q245nJuu/DoZzteAaBe33UGB81lHOvz1qPfch9n0QCW0xSNm9bTK7gfjxjxt6Wx8L+AVtkU8Zwjmctx/KP23j88fzzhAKXqrPowIEDfLEdAEwCbW1tmjVr1ufWjLshVCqVdPDgQaVSqRFfhtfb26vGxka1tbWpqqrK4wrHFts5eZwL2yixnZPNaGxnEATq6+tTQ0ODwuHP/2vFuPtzXDgc/tzJWVVVNalPgOPYzsnjXNhGie2cbM50O9PptFMdb0wAAHjDEAIAeDNhhlAikdCaNWuUSNi+nGqiYTsnj3NhGyW2c7I529s57t6YAAA4d0yYZ0IAgMmHIQQA8IYhBADwhiEEAPCGIQQA8GbCDKFHHnlETU1NKisr06WXXqrf/OY3vpc0qlpbWxUKhUZc6urqfC/rjGzbtk3Lli1TQ0ODQqGQnn322RG3B0Gg1tZWNTQ0KJlMaunSpXr77bf9LPYMfNF23nbbbScc20WLFvlZ7Glat26dLrvsMqVSKdXU1OjGG2/U+++/P6JmMhxPl+2cDMdz48aNmj9//nAqwuLFi/Xiiy8O3342j+WEGEJPPfWUVq5cqfvvv1+7d+/WlVdeqZaWFu3fv9/30kbVxRdfrPb29uHLnj17fC/pjAwMDGjBggXasGHDSW9/8MEHtX79em3YsEE7d+5UXV2drrvuOvX19Z3llZ6ZL9pOSbr++utHHNsXXnjhLK7wzG3dulV33XWXduzYoc2bN6tQKKi5uVkDAwPDNZPheLpspzTxj+esWbP0wAMPaNeuXdq1a5euvfZa3XDDDcOD5qwey2AC+MY3vhHccccdI6778pe/HPz0pz/1tKLRt2bNmmDBggW+lzFmJAXPPPPM8L9LpVJQV1cXPPDAA8PXDQ0NBel0Ovinf/onDyscHZ/dziAIghUrVgQ33HCDl/WMlc7OzkBSsHXr1iAIJu/x/Ox2BsHkPJ5BEARTp04NfvWrX531Yznunwnlcjm98cYbam5uHnF9c3Oztm/f7mlVY2Pv3r1qaGhQU1OTvve97+nDDz/0vaQxs2/fPnV0dIw4rolEQldfffWkO66StGXLFtXU1Gju3Lm6/fbb1dnZ6XtJZ6Snp0eSVF1dLWnyHs/Pbudxk+l4FotFPfnkkxoYGNDixYvP+rEc90PoyJEjKhaLqq2tHXF9bW2tOjo6PK1q9F1++eV6/PHH9fLLL+uXv/ylOjo6tGTJEh09etT30sbE8WM32Y+rJLW0tOiJJ57Qq6++qoceekg7d+7Utddeq2w263tppyUIAq1atUpXXHGF5s2bJ2lyHs+Tbac0eY7nnj17VFlZqUQioTvuuEPPPPOMvvrVr571YznuvsrhVP70u4WkT0+Qz143kbW0tAz/9yWXXKLFixfrggsu0GOPPaZVq1Z5XNnYmuzHVZJuvvnm4f+eN2+eFi5cqNmzZ+v555/X8uXLPa7s9Nx9991666239Prrr59w22Q6nqfazslyPC+66CK9+eab6u7u1r/9279pxYoV2rp16/DtZ+tYjvtnQtOnT1ckEjlhAnd2dp4wqSeTiooKXXLJJdq7d6/vpYyJ4+/8O9eOqyTV19dr9uzZE/LY3nPPPXruuef02muvjfjer8l2PE+1nSczUY9nPB7XhRdeqIULF2rdunVasGCBfvGLX5z1Yznuh1A8Htell16qzZs3j7h+8+bNWrJkiadVjb1sNqt3331X9fX1vpcyJpqamlRXVzfiuOZyOW3dunVSH1dJOnr0qNra2ibUsQ2CQHfffbeefvppvfrqq2pqahpx+2Q5nl+0nSczEY/nyQRBoGw2e/aP5ai/1WEMPPnkk0EsFgt+/etfB++8806wcuXKoKKiIvjoo498L23U/OhHPwq2bNkSfPjhh8GOHTuC73znO0EqlZrQ29jX1xfs3r072L17dyApWL9+fbB79+7g448/DoIgCB544IEgnU4HTz/9dLBnz57g+9//flBfXx/09vZ6XrnN521nX19f8KMf/SjYvn17sG/fvuC1114LFi9eHMycOXNCbecPf/jDIJ1OB1u2bAna29uHL4ODg8M1k+F4ftF2TpbjuXr16mDbtm3Bvn37grfeeiu47777gnA4HLzyyitBEJzdYzkhhlAQBME//uM/BrNnzw7i8Xjw9a9/fcRbJieDm2++Oaivrw9isVjQ0NAQLF++PHj77bd9L+uMvPbaa4GkEy4rVqwIguDTt/WuWbMmqKurCxKJRHDVVVcFe/bs8bvo0/B52zk4OBg0NzcHM2bMCGKxWHDeeecFK1asCPbv3+972SYn2z5JwaOPPjpcMxmO5xdt52Q5nn/91389/Hg6Y8aM4Jvf/ObwAAqCs3ss+T4hAIA34/41IQDA5MUQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB48/8DODvqtnpTd/sAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#display one of the training examples and its label\n",
        "plt.imshow(train_data_norm.data[0], cmap='gray')\n",
        "plt.title('%i' % train_data_norm.targets[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P5kJ8mwhbxr",
        "outputId": "8fd96f95-8a78-46ec-c559-9e05577c8b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/250], Loss: 2.1217\n",
            "Epoch [1/10], Step [200/250], Loss: 2.0291\n",
            "Epoch [2/10], Step [100/250], Loss: 1.8560\n",
            "Epoch [2/10], Step [200/250], Loss: 1.8091\n",
            "Epoch [3/10], Step [100/250], Loss: 1.7451\n",
            "Epoch [3/10], Step [200/250], Loss: 1.7052\n",
            "Epoch [4/10], Step [100/250], Loss: 1.6973\n",
            "Epoch [4/10], Step [200/250], Loss: 1.4815\n",
            "Epoch [5/10], Step [100/250], Loss: 1.4741\n",
            "Epoch [5/10], Step [200/250], Loss: 1.4867\n",
            "Epoch [6/10], Step [100/250], Loss: 1.3532\n",
            "Epoch [6/10], Step [200/250], Loss: 1.4092\n",
            "Epoch [7/10], Step [100/250], Loss: 1.4992\n",
            "Epoch [7/10], Step [200/250], Loss: 1.3323\n",
            "Epoch [8/10], Step [100/250], Loss: 1.4404\n",
            "Epoch [8/10], Step [200/250], Loss: 1.3365\n",
            "Epoch [9/10], Step [100/250], Loss: 1.3571\n",
            "Epoch [9/10], Step [200/250], Loss: 1.3375\n",
            "Epoch [10/10], Step [100/250], Loss: 1.3129\n",
            "Epoch [10/10], Step [200/250], Loss: 1.3178\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LncC8m9uj2K-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 53.11%\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "model.test_model(test_loader_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "- The initial architecture is the same as the one used on MNIST with the input channels of the first layer and dense layers updated for larger image size. After 10 epochs the loss is 1.31 with a downwar trend. The accuracy is 53.11%\n",
        "## Analysis\n",
        "\n",
        "- The model is not learning enough. I will increase the number of parameters to better fit the training data by dowbling the number of chanels at each conv layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\" \n",
        "  Implements a Convolutional Neural Network for Classification\n",
        "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        #input image shape 28x28x3 and apply convolutional layer with same padding\n",
        "        nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5,stride=1,padding=2),\n",
        "        #new shape 28x28x16\n",
        "        nn.ReLU(),\n",
        "        #new shape 14x14x16\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        # input shape 14x14x16\n",
        "        nn.Conv2d(16, 32, 5, 1, 2),\n",
        "        # new shape 14x14x32\n",
        "        nn.ReLU(),\n",
        "        # 7x7x32\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.out = nn.Linear(32* 8 * 8, 10)\n",
        "  def forward(self, x):\n",
        "    #print(f\"The input shape is {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"The shape after the first conv layer {x.shape}\")\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"The shape after the third conv layer {x.shape}\")\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(f\"The shape after flatening {x.shape}\")\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "\n",
        "  def train_model(self, num_epochs, train_loader, lr):\n",
        "    self.train()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            #compute the forward pass\n",
        "            output = self(images)\n",
        "            #compute the loss\n",
        "            loss = loss_function(output, labels)\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "                \n",
        "  def test_model(self, test_loader):\n",
        "    self.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass to get output/logits\n",
        "          outputs = self(images)\n",
        "          \n",
        "          # Predictions are the maximum value locations in logits dimension\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          \n",
        "          # Collect the predictions and labels\n",
        "          predictions.extend(predicted.cpu().numpy())\n",
        "          labels_list.extend(labels.cpu().numpy())\n",
        "    correct = (np.array(predictions) == np.array(labels_list)).sum()\n",
        "    total = len(labels_list)\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy * 100:.2f}%') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/250], Loss: 2.1680\n",
            "Epoch [1/10], Step [200/250], Loss: 1.9632\n",
            "Epoch [2/10], Step [100/250], Loss: 1.9248\n",
            "Epoch [2/10], Step [200/250], Loss: 1.7721\n",
            "Epoch [3/10], Step [100/250], Loss: 1.7087\n",
            "Epoch [3/10], Step [200/250], Loss: 1.6420\n",
            "Epoch [4/10], Step [100/250], Loss: 1.5856\n",
            "Epoch [4/10], Step [200/250], Loss: 1.5278\n",
            "Epoch [5/10], Step [100/250], Loss: 1.4903\n",
            "Epoch [5/10], Step [200/250], Loss: 1.5784\n",
            "Epoch [6/10], Step [100/250], Loss: 1.4299\n",
            "Epoch [6/10], Step [200/250], Loss: 1.5672\n",
            "Epoch [7/10], Step [100/250], Loss: 1.2949\n",
            "Epoch [7/10], Step [200/250], Loss: 1.3648\n",
            "Epoch [8/10], Step [100/250], Loss: 1.2876\n",
            "Epoch [8/10], Step [200/250], Loss: 1.3680\n",
            "Epoch [9/10], Step [100/250], Loss: 1.4088\n",
            "Epoch [9/10], Step [200/250], Loss: 1.3944\n",
            "Epoch [10/10], Step [100/250], Loss: 1.3652\n",
            "Epoch [10/10], Step [200/250], Loss: 1.2251\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 10\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 54.44%\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "model.test_model(test_loader_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "- Doubling the number of output channels lowered the loss slightly to 1.22 and the accuracy went up to 54.8%. \n",
        "## Analysis\n",
        "\n",
        "- Not much improvement was found by doubling the number of channels. The model is still not learning enough. I will add a third conv block with a conv layer, relu, conv layer. \n",
        "- Changed the filters to collapse the images faster and added more channels\n",
        "- Added momentum to help GSD make progress. Loss was not progressing without it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\" \n",
        "  Implements a Convolutional Neural Network for Classification\n",
        "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        #input image shape 28x28x3 and apply convolutional layer with same padding\n",
        "        nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
        "        #new shape 28x28x32\n",
        "        nn.ReLU(),\n",
        "        #new shape 16x16x32\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        # input shape 14x14x32\n",
        "        nn.Conv2d(32, 64, 2, 2, 1),\n",
        "        # new shape 14x14x32\n",
        "        nn.ReLU(),\n",
        "        # 7x7x64\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        # input shape 7x7x64\n",
        "        nn.Conv2d(64, 128, 5, 1, 1),\n",
        "        # new shape 7x7x128\n",
        "        nn.ReLU(),\n",
        "        # 3x3x128\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.fc1 = nn.Linear(128, 256)\n",
        "    self.out = nn.Linear(256, 10)\n",
        "  def forward(self, x):\n",
        "    #print(f\"The input shape is {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"The shape after the first conv layer {x.shape}\")\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"The shape after the second conv layer {x.shape}\")\n",
        "    x = self.conv3(x)\n",
        "    #print(f\"The shape after the third conv layer {x.shape}\")\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(f\"The shape after flatening {x.shape}\")\n",
        "    x = F.relu(self.fc1(x))\n",
        "    #print(f\"The shape after linear {x.shape}\")\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "\n",
        "  def train_model(self, num_epochs, train_loader, lr):\n",
        "    self.train()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            #compute the forward pass\n",
        "            output = self(images)\n",
        "            #compute the loss\n",
        "            loss = loss_function(output, labels)\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "                \n",
        "  def test_model(self, test_loader):\n",
        "    self.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass to get output/logits\n",
        "          outputs = self(images)\n",
        "          \n",
        "          # Predictions are the maximum value locations in logits dimension\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          \n",
        "          # Collect the predictions and labels\n",
        "          predictions.extend(predicted.cpu().numpy())\n",
        "          labels_list.extend(labels.cpu().numpy())\n",
        "    correct = (np.array(predictions) == np.array(labels_list)).sum()\n",
        "    total = len(labels_list)\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy * 100:.2f}%') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/250], Loss: 2.1964\n",
            "Epoch [1/10], Step [200/250], Loss: 1.9447\n",
            "Epoch [2/10], Step [100/250], Loss: 1.6762\n",
            "Epoch [2/10], Step [200/250], Loss: 1.6300\n",
            "Epoch [3/10], Step [100/250], Loss: 1.4586\n",
            "Epoch [3/10], Step [200/250], Loss: 1.3669\n",
            "Epoch [4/10], Step [100/250], Loss: 1.2604\n",
            "Epoch [4/10], Step [200/250], Loss: 1.1511\n",
            "Epoch [5/10], Step [100/250], Loss: 1.0764\n",
            "Epoch [5/10], Step [200/250], Loss: 1.1905\n",
            "Epoch [6/10], Step [100/250], Loss: 1.0249\n",
            "Epoch [6/10], Step [200/250], Loss: 1.0513\n",
            "Epoch [7/10], Step [100/250], Loss: 0.9417\n",
            "Epoch [7/10], Step [200/250], Loss: 0.9679\n",
            "Epoch [8/10], Step [100/250], Loss: 0.9305\n",
            "Epoch [8/10], Step [200/250], Loss: 0.7323\n",
            "Epoch [9/10], Step [100/250], Loss: 0.7423\n",
            "Epoch [9/10], Step [200/250], Loss: 0.9601\n",
            "Epoch [10/10], Step [100/250], Loss: 0.7352\n",
            "Epoch [10/10], Step [200/250], Loss: 0.7977\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 10\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 68.93%\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "model.test_model(test_loader_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "- The changes improved the performance tremendously to 68.93% accuracy.\n",
        "## Analysis\n",
        "- The model needs to train for longer. I will add learning rate decay and train for 10 epochs and assess the performance.\n",
        "- I may also add batch normalization if I notice that the variance between the loss of the batches is too high.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The input shape is torch.Size([200, 3, 32, 32])\n",
        "The shape after the first conv layer torch.Size([200, 32, 16, 16])\n",
        "The shape after the second conv layer torch.Size([200, 64, 4, 4])\n",
        "The shape after the third conv layer torch.Size([200, 128, 1, 1])\n",
        "The shape after flatening torch.Size([200, 128])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\" \n",
        "  Implements a Convolutional Neural Network for Classification\n",
        "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        #input image shape 28x28x3 and apply convolutional layer with same padding\n",
        "        nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
        "        #new shape 28x28x32\n",
        "        nn.BatchNorm2d(num_features=32),\n",
        "        nn.ReLU(),\n",
        "        #new shape 16x16x32\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        # input shape 14x14x32\n",
        "        nn.Conv2d(32, 64, 2, 2, 1),\n",
        "        nn.BatchNorm2d(num_features=64),\n",
        "        # new shape 14x14x32\n",
        "        nn.ReLU(),\n",
        "        # 7x7x64\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        # input shape 7x7x64\n",
        "        nn.Conv2d(64, 128, 5, 1, 1),\n",
        "        # new shape 7x7x128\n",
        "        nn.BatchNorm2d(num_features=128),\n",
        "        nn.ReLU(),\n",
        "        # 3x3x128\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    \n",
        "    self.fc1 = nn.Linear(128, 256)\n",
        "    #self.bn1 = nn.BatchNorm1d(num_features=256)\n",
        "    self.out = nn.Linear(256, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    #print(f\"The input shape is {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"The shape after the first conv layer {x.shape}\")\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"The shape after the second conv layer {x.shape}\")\n",
        "    x = self.conv3(x)\n",
        "    #print(f\"The shape after the third conv layer {x.shape}\")\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(f\"The shape after flatening {x.shape}\")\n",
        "    x = F.relu(self.fc1(x))\n",
        "    #x = self.bn1(x)\n",
        "    #print(f\"The shape after linear {x.shape}\")\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "\n",
        "  def train_model(self, num_epochs, train_loader, lr):\n",
        "    self.train()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            #compute the forward pass\n",
        "            output = self(images)\n",
        "            #compute the loss\n",
        "            loss = loss_function(output, labels)\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "        #scheduler.step()\n",
        "        #current_lr = scheduler.get_last_lr()[0]  # get_last_lr returns a list, we get the first element\n",
        "        \n",
        "          # Custom learning rate scheduling\n",
        "        if epoch < 3:\n",
        "            lr = lr * 0.9  # Decay learning rate\n",
        "        elif epoch < 5:\n",
        "            lr = lr * 0.85\n",
        "        elif epoch < 15:\n",
        "            lr = lr * 0.8\n",
        "        else:\n",
        "            lr = lr * 0.5\n",
        "\n",
        "        # Manually update the learning rates for all parameters in the optimizer\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        \n",
        "        print(f'End of Epoch {epoch + 1}, Current Learning Rate: {lr}')     \n",
        "  def test_model(self, test_loader):\n",
        "    self.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass to get output/logits\n",
        "          outputs = self(images)\n",
        "          \n",
        "          # Predictions are the maximum value locations in logits dimension\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          \n",
        "          # Collect the predictions and labels\n",
        "          predictions.extend(predicted.cpu().numpy())\n",
        "          labels_list.extend(labels.cpu().numpy())\n",
        "    correct = (np.array(predictions) == np.array(labels_list)).sum()\n",
        "    total = len(labels_list)\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy * 100:.2f}%') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/250], Loss: 1.3666\n",
            "Epoch [1/20], Step [200/250], Loss: 1.2302\n",
            "End of Epoch 1, Current Learning Rate: 0.09000000000000001\n",
            "Epoch [2/20], Step [100/250], Loss: 0.9974\n",
            "Epoch [2/20], Step [200/250], Loss: 0.9195\n",
            "End of Epoch 2, Current Learning Rate: 0.08100000000000002\n",
            "Epoch [3/20], Step [100/250], Loss: 0.8740\n",
            "Epoch [3/20], Step [200/250], Loss: 0.7074\n",
            "End of Epoch 3, Current Learning Rate: 0.07290000000000002\n",
            "Epoch [4/20], Step [100/250], Loss: 0.5951\n",
            "Epoch [4/20], Step [200/250], Loss: 0.5298\n",
            "End of Epoch 4, Current Learning Rate: 0.06196500000000001\n",
            "Epoch [5/20], Step [100/250], Loss: 0.5633\n",
            "Epoch [5/20], Step [200/250], Loss: 0.6771\n",
            "End of Epoch 5, Current Learning Rate: 0.05267025000000001\n",
            "Epoch [6/20], Step [100/250], Loss: 0.3484\n",
            "Epoch [6/20], Step [200/250], Loss: 0.4554\n",
            "End of Epoch 6, Current Learning Rate: 0.04213620000000001\n",
            "Epoch [7/20], Step [100/250], Loss: 0.3192\n",
            "Epoch [7/20], Step [200/250], Loss: 0.3278\n",
            "End of Epoch 7, Current Learning Rate: 0.03370896000000001\n",
            "Epoch [8/20], Step [100/250], Loss: 0.2702\n",
            "Epoch [8/20], Step [200/250], Loss: 0.2136\n",
            "End of Epoch 8, Current Learning Rate: 0.02696716800000001\n",
            "Epoch [9/20], Step [100/250], Loss: 0.1198\n",
            "Epoch [9/20], Step [200/250], Loss: 0.1746\n",
            "End of Epoch 9, Current Learning Rate: 0.02157373440000001\n",
            "Epoch [10/20], Step [100/250], Loss: 0.0826\n",
            "Epoch [10/20], Step [200/250], Loss: 0.1440\n",
            "End of Epoch 10, Current Learning Rate: 0.01725898752000001\n",
            "Epoch [11/20], Step [100/250], Loss: 0.0777\n",
            "Epoch [11/20], Step [200/250], Loss: 0.0835\n",
            "End of Epoch 11, Current Learning Rate: 0.013807190016000007\n",
            "Epoch [12/20], Step [100/250], Loss: 0.0689\n",
            "Epoch [12/20], Step [200/250], Loss: 0.0584\n",
            "End of Epoch 12, Current Learning Rate: 0.011045752012800007\n",
            "Epoch [13/20], Step [100/250], Loss: 0.0229\n",
            "Epoch [13/20], Step [200/250], Loss: 0.0282\n",
            "End of Epoch 13, Current Learning Rate: 0.008836601610240006\n",
            "Epoch [14/20], Step [100/250], Loss: 0.0230\n",
            "Epoch [14/20], Step [200/250], Loss: 0.0214\n",
            "End of Epoch 14, Current Learning Rate: 0.007069281288192005\n",
            "Epoch [15/20], Step [100/250], Loss: 0.0277\n",
            "Epoch [15/20], Step [200/250], Loss: 0.0428\n",
            "End of Epoch 15, Current Learning Rate: 0.005655425030553604\n",
            "Epoch [16/20], Step [100/250], Loss: 0.0096\n",
            "Epoch [16/20], Step [200/250], Loss: 0.0244\n",
            "End of Epoch 16, Current Learning Rate: 0.002827712515276802\n",
            "Epoch [17/20], Step [100/250], Loss: 0.0106\n",
            "Epoch [17/20], Step [200/250], Loss: 0.0116\n",
            "End of Epoch 17, Current Learning Rate: 0.001413856257638401\n",
            "Epoch [18/20], Step [100/250], Loss: 0.0071\n",
            "Epoch [18/20], Step [200/250], Loss: 0.0129\n",
            "End of Epoch 18, Current Learning Rate: 0.0007069281288192005\n",
            "Epoch [19/20], Step [100/250], Loss: 0.0070\n",
            "Epoch [19/20], Step [200/250], Loss: 0.0104\n",
            "End of Epoch 19, Current Learning Rate: 0.00035346406440960027\n",
            "Epoch [20/20], Step [100/250], Loss: 0.0082\n",
            "Epoch [20/20], Step [200/250], Loss: 0.0114\n",
            "End of Epoch 20, Current Learning Rate: 0.00017673203220480013\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .1\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 20\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 74.16%\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "model.test_model(test_loader_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "- Learning rate decay improved the performance  to 70.22% accuracy. \n",
        "- Adding Batch normalization lead to a slightly lower test accuracy  69.57% which indicates the model may be starting to overfit. \n",
        "- Removing the last normalization layer lead to an increase in accuracy to 71.75%\n",
        "- Custum learning rate decay lead to an increase of accuacy to 74.63%\n",
        "- Further cusumization of learning rate schedule lead to a mooderate improvement of 74.86%\n",
        "## Analysis\n",
        "- I increased the learning rate to .1 and decreased it by 90% each epoch for 10 epochs\n",
        "- Decay is helping. I am not going to add batch normalization layers and see if these have a positive effect on training time, losses, and or accuracy.\n",
        "- Trying by removing the last normalization layer after the linear activation.\n",
        "- Costum rate decay is working better. I am now going to try to train for longer and split up the schedule a bit more. \n",
        "- The current schedule gives slightly higher accuracy but after epoch 14 the model is not learning a whole lot.\n",
        "- I am going to try to stabilize the learning rate so it doesnt decay so quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\" \n",
        "  Implements a Convolutional Neural Network for Classification\n",
        "    ZEROPAD2D -> CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Sequential(\n",
        "        #input image shape 32x32x3 and apply convolutional layer with same padding\n",
        "        nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(num_features=32),\n",
        "        nn.ReLU(),\n",
        "        #new shape 32 -3 +2 /1 +1= 32 => 32x32x32\n",
        "        nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
        "        nn.BatchNorm2d(num_features=64),\n",
        "        nn.ReLU(),\n",
        "        #new shape 32 -3 +2 /1 +1= 32 => 32x32x64\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        #new shape 32 -2 /2 +1= 31 => 16x16x64\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        # input shape 16x16x64\n",
        "        nn.Conv2d(64, 128, 3, 1, 1),\n",
        "        nn.BatchNorm2d(num_features=128),\n",
        "        # new shape 16x16x128\n",
        "        nn.ReLU(),\n",
        "         # input shape \n",
        "        nn.Conv2d(128, 264, 3, 2, 1),\n",
        "        nn.BatchNorm2d(num_features=264),\n",
        "        # new shape 8x8x264\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        #new shape 8 -2 /2 +1= 8=> 4x4x264\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        # input shape 4x4x64\n",
        "        nn.Conv2d(264, 528, 2, 1, 0),\n",
        "        # new shape 3x3x128\n",
        "        nn.BatchNorm2d(num_features=528),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(528, 528*2, 2, 1, 0),\n",
        "        # new shape 7x7x128\n",
        "        nn.BatchNorm2d(num_features=528 *2),\n",
        "        nn.ReLU(),\n",
        "        # 3x3x128\n",
        "        nn.MaxPool2d(2),\n",
        "    )\n",
        "    \n",
        "    self.fc1 = nn.Linear(1056,528)\n",
        "    #self.bn1 = nn.BatchNorm1d(num_features=256)\n",
        "    self.out = nn.Linear(528, 10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    #print(f\"The input shape is {x.shape}\")\n",
        "    x = self.conv1(x)\n",
        "    #print(f\"The shape after the first conv layer {x.shape}\")\n",
        "    x = self.conv2(x)\n",
        "    #print(f\"The shape after the second conv layer {x.shape}\")\n",
        "    x = self.conv3(x)\n",
        "    #print(f\"The shape after the third conv layer {x.shape}\")\n",
        "    # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    #print(f\"The shape after flatening {x.shape}\")\n",
        "    x = F.relu(self.fc1(x))\n",
        "    #x = self.bn1(x)\n",
        "    #print(f\"The shape after linear {x.shape}\")\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "  def validate_model(self,val_loader):\n",
        "    self.eval()  # Switch to evaluation mode\n",
        "    loss_function = nn.CrossEntropyLoss()  # Loss function\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "    total_correct = 0\n",
        "    \n",
        "    with torch.no_grad():  # Disables gradient calculation\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = self(images)\n",
        "            \n",
        "            # Calculate the loss\n",
        "            loss = loss_function(outputs, labels)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_samples += images.size(0)\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    average_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Validation Loss: {average_loss:.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
        "    return average_loss, accuracy\n",
        "  def train_model(self, num_epochs, train_loader,val_loader, lr):\n",
        "    self.train()\n",
        "    optimizer = optim.SGD(self.parameters(), lr=lr, momentum=0.9,weight_decay=0.01)\n",
        "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_step = len(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            #compute the forward pass\n",
        "            output = self(images)\n",
        "            #compute the loss\n",
        "            loss = loss_function(output, labels)\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "        #scheduler.step()\n",
        "        #current_lr = scheduler.get_last_lr()[0]  # get_last_lr returns a list, we get the first element\n",
        "        \n",
        "          # Custom learning rate scheduling\n",
        "        if epoch < 3:\n",
        "            lr = lr * 0.9  # Decay learning rate\n",
        "        elif epoch < 5:\n",
        "            lr = lr * 0.85\n",
        "        elif epoch < 15:\n",
        "            lr = lr * 0.8\n",
        "        else:\n",
        "            lr = lr * 0.75\n",
        "\n",
        "        # Manually update the learning rates for all parameters in the optimizer\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        \n",
        "        print(f'End of Epoch {epoch + 1}, Current Learning Rate: {lr}')\n",
        "        self.validate_model(val_loader)  \n",
        "  def test_model(self, test_loader):\n",
        "    self.eval()\n",
        "    predictions = []\n",
        "    labels_list = []\n",
        "    with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          \n",
        "          # Forward pass to get output/logits\n",
        "          outputs = self(images)\n",
        "          \n",
        "          # Predictions are the maximum value locations in logits dimension\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          \n",
        "          # Collect the predictions and labels\n",
        "          predictions.extend(predicted.cpu().numpy())\n",
        "          labels_list.extend(labels.cpu().numpy())\n",
        "    correct = (np.array(predictions) == np.array(labels_list)).sum()\n",
        "    total = len(labels_list)\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy of the network on the test images: {accuracy * 100:.2f}%') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "The size of the train data 40000\n",
            "The size of the validation data 10000\n",
            "The size of the test data 10000\n"
          ]
        }
      ],
      "source": [
        "#Load Data:\n",
        "# train_data = datasets.MNIST(root = 'data', train = True, transform = transforms.ToTensor(),download = True)\n",
        "# test_data = datasets.MNIST(root = 'data', train = False,transform = transforms.ToTensor())\n",
        "\n",
        "train_data_norm = datasets.CIFAR10(root = 'data', train = True, transform = transform1,download = True)\n",
        "test_data_norm = datasets.CIFAR10(root = 'data', train = False,transform = transform1)\n",
        "\n",
        "# Define sizes for split\n",
        "num_train = len(train_data_norm)\n",
        "num_val = int(0.2 * num_train)  # Let's use 20% of the training data for validation\n",
        "num_train = num_train - num_val\n",
        "\n",
        "# Split the data into train and validation sets\n",
        "train_data_norm, val_data_norm = torch.utils.data.random_split(train_data_norm, [num_train, num_val])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"The size of the train data\", len(train_data_norm))\n",
        "print(\"The size of the validation data\",len(val_data_norm))\n",
        "print(\"The size of the test data\", len(test_data_norm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/200], Loss: 1.3172\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[128], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN()\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_1\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[125], line 101\u001b[0m, in \u001b[0;36mCNN.train_model\u001b[0;34m(self, num_epochs, train_loader, val_loader, lr)\u001b[0m\n\u001b[1;32m     99\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# backpropagation, compute gradients\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# apply gradients\u001b[39;00m\n\u001b[1;32m    103\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/my-special-env/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/my-special-env/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 20\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "val_loader_norm = torch.utils.data.DataLoader(val_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm,val_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[129], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN()\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_1\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[125], line 101\u001b[0m, in \u001b[0;36mCNN.train_model\u001b[0;34m(self, num_epochs, train_loader, val_loader, lr)\u001b[0m\n\u001b[1;32m     99\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# backpropagation, compute gradients\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# apply gradients\u001b[39;00m\n\u001b[1;32m    103\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/my-special-env/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/my-special-env/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 20\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "val_loader_norm = torch.utils.data.DataLoader(val_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm,val_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/200], Loss: 1.3439\n",
            "Epoch [1/20], Step [200/200], Loss: 1.1573\n",
            "End of Epoch 1, Current Learning Rate: 0.009000000000000001\n",
            "Validation Loss: 1.2723, Accuracy: 54.43%\n",
            "Epoch [2/20], Step [100/200], Loss: 1.1603\n",
            "Epoch [2/20], Step [200/200], Loss: 0.9997\n",
            "End of Epoch 2, Current Learning Rate: 0.008100000000000001\n",
            "Validation Loss: 1.0598, Accuracy: 62.32%\n",
            "Epoch [3/20], Step [100/200], Loss: 1.0403\n",
            "Epoch [3/20], Step [200/200], Loss: 1.0324\n",
            "End of Epoch 3, Current Learning Rate: 0.007290000000000001\n",
            "Validation Loss: 1.0061, Accuracy: 64.45%\n",
            "Epoch [4/20], Step [100/200], Loss: 0.9414\n",
            "Epoch [4/20], Step [200/200], Loss: 0.8540\n",
            "End of Epoch 4, Current Learning Rate: 0.006196500000000001\n",
            "Validation Loss: 1.0021, Accuracy: 64.60%\n",
            "Epoch [5/20], Step [100/200], Loss: 0.8910\n",
            "Epoch [5/20], Step [200/200], Loss: 0.7780\n",
            "End of Epoch 5, Current Learning Rate: 0.005267025000000001\n",
            "Validation Loss: 0.8843, Accuracy: 69.43%\n",
            "Epoch [6/20], Step [100/200], Loss: 0.6869\n",
            "Epoch [6/20], Step [200/200], Loss: 0.8100\n",
            "End of Epoch 6, Current Learning Rate: 0.00421362\n",
            "Validation Loss: 0.8466, Accuracy: 70.61%\n",
            "Epoch [7/20], Step [100/200], Loss: 0.9237\n",
            "Epoch [7/20], Step [200/200], Loss: 0.6345\n",
            "End of Epoch 7, Current Learning Rate: 0.0033708960000000004\n",
            "Validation Loss: 0.8473, Accuracy: 70.93%\n",
            "Epoch [8/20], Step [100/200], Loss: 0.6335\n",
            "Epoch [8/20], Step [200/200], Loss: 0.6445\n",
            "End of Epoch 8, Current Learning Rate: 0.0026967168000000003\n",
            "Validation Loss: 0.8264, Accuracy: 71.61%\n",
            "Epoch [9/20], Step [100/200], Loss: 0.6715\n",
            "Epoch [9/20], Step [200/200], Loss: 0.5558\n",
            "End of Epoch 9, Current Learning Rate: 0.00215737344\n",
            "Validation Loss: 0.8096, Accuracy: 72.46%\n",
            "Epoch [10/20], Step [100/200], Loss: 0.5574\n",
            "Epoch [10/20], Step [200/200], Loss: 0.5368\n",
            "End of Epoch 10, Current Learning Rate: 0.0017258987520000003\n",
            "Validation Loss: 0.8020, Accuracy: 72.55%\n",
            "Epoch [11/20], Step [100/200], Loss: 0.5664\n",
            "Epoch [11/20], Step [200/200], Loss: 0.5897\n",
            "End of Epoch 11, Current Learning Rate: 0.0013807190016000004\n",
            "Validation Loss: 0.8044, Accuracy: 72.34%\n",
            "Epoch [12/20], Step [100/200], Loss: 0.4429\n",
            "Epoch [12/20], Step [200/200], Loss: 0.4173\n",
            "End of Epoch 12, Current Learning Rate: 0.0011045752012800003\n",
            "Validation Loss: 0.7987, Accuracy: 73.01%\n",
            "Epoch [13/20], Step [100/200], Loss: 0.5368\n",
            "Epoch [13/20], Step [200/200], Loss: 0.4547\n",
            "End of Epoch 13, Current Learning Rate: 0.0008836601610240002\n",
            "Validation Loss: 0.7960, Accuracy: 73.19%\n",
            "Epoch [14/20], Step [100/200], Loss: 0.4906\n",
            "Epoch [14/20], Step [200/200], Loss: 0.5482\n",
            "End of Epoch 14, Current Learning Rate: 0.0007069281288192002\n",
            "Validation Loss: 0.8148, Accuracy: 72.21%\n",
            "Epoch [15/20], Step [100/200], Loss: 0.4120\n",
            "Epoch [15/20], Step [200/200], Loss: 0.5240\n",
            "End of Epoch 15, Current Learning Rate: 0.0005655425030553602\n",
            "Validation Loss: 0.7929, Accuracy: 73.16%\n",
            "Epoch [16/20], Step [100/200], Loss: 0.3922\n",
            "Epoch [16/20], Step [200/200], Loss: 0.4066\n",
            "End of Epoch 16, Current Learning Rate: 0.00042415687729152016\n",
            "Validation Loss: 0.7998, Accuracy: 72.92%\n",
            "Epoch [17/20], Step [100/200], Loss: 0.5209\n",
            "Epoch [17/20], Step [200/200], Loss: 0.4586\n",
            "End of Epoch 17, Current Learning Rate: 0.0003181176579686401\n",
            "Validation Loss: 0.7960, Accuracy: 72.98%\n",
            "Epoch [18/20], Step [100/200], Loss: 0.4079\n",
            "Epoch [18/20], Step [200/200], Loss: 0.3548\n",
            "End of Epoch 18, Current Learning Rate: 0.00023858824347648008\n",
            "Validation Loss: 0.7976, Accuracy: 73.17%\n",
            "Epoch [19/20], Step [100/200], Loss: 0.3263\n",
            "Epoch [19/20], Step [200/200], Loss: 0.3810\n",
            "End of Epoch 19, Current Learning Rate: 0.00017894118260736007\n",
            "Validation Loss: 0.7975, Accuracy: 73.17%\n",
            "Epoch [20/20], Step [100/200], Loss: 0.4023\n",
            "Epoch [20/20], Step [200/200], Loss: 0.4517\n",
            "End of Epoch 20, Current Learning Rate: 0.00013420588695552005\n",
            "Validation Loss: 0.7934, Accuracy: 73.45%\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 20\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "val_loader_norm = torch.utils.data.DataLoader(val_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm,val_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/200], Loss: 1.2449\n",
            "Epoch [1/20], Step [200/200], Loss: 0.8929\n",
            "End of Epoch 1, Current Learning Rate: 0.009000000000000001\n",
            "Validation Loss: 1.0550, Accuracy: 62.82%\n",
            "Epoch [2/20], Step [100/200], Loss: 1.9083\n",
            "Epoch [2/20], Step [200/200], Loss: 1.6868\n",
            "End of Epoch 2, Current Learning Rate: 0.008100000000000001\n",
            "Validation Loss: 1.7002, Accuracy: 35.29%\n",
            "Epoch [3/20], Step [100/200], Loss: 1.6551\n",
            "Epoch [3/20], Step [200/200], Loss: 1.5351\n",
            "End of Epoch 3, Current Learning Rate: 0.007290000000000001\n",
            "Validation Loss: 1.4092, Accuracy: 49.16%\n",
            "Epoch [4/20], Step [100/200], Loss: 1.3624\n",
            "Epoch [4/20], Step [200/200], Loss: 1.2219\n",
            "End of Epoch 4, Current Learning Rate: 0.006196500000000001\n",
            "Validation Loss: 1.2401, Accuracy: 54.42%\n",
            "Epoch [5/20], Step [100/200], Loss: 1.1769\n",
            "Epoch [5/20], Step [200/200], Loss: 1.0334\n",
            "End of Epoch 5, Current Learning Rate: 0.005267025000000001\n",
            "Validation Loss: 1.1035, Accuracy: 59.78%\n",
            "Epoch [6/20], Step [100/200], Loss: 0.9639\n",
            "Epoch [6/20], Step [200/200], Loss: 0.9587\n",
            "End of Epoch 6, Current Learning Rate: 0.00421362\n",
            "Validation Loss: 1.0506, Accuracy: 62.26%\n",
            "Epoch [7/20], Step [100/200], Loss: 0.8577\n",
            "Epoch [7/20], Step [200/200], Loss: 0.9915\n",
            "End of Epoch 7, Current Learning Rate: 0.0033708960000000004\n",
            "Validation Loss: 0.9489, Accuracy: 66.34%\n",
            "Epoch [8/20], Step [100/200], Loss: 1.0353\n",
            "Epoch [8/20], Step [200/200], Loss: 0.8541\n",
            "End of Epoch 8, Current Learning Rate: 0.0026967168000000003\n",
            "Validation Loss: 0.8731, Accuracy: 68.66%\n",
            "Epoch [9/20], Step [100/200], Loss: 0.9397\n",
            "Epoch [9/20], Step [200/200], Loss: 0.6792\n",
            "End of Epoch 9, Current Learning Rate: 0.00215737344\n",
            "Validation Loss: 0.8535, Accuracy: 69.11%\n",
            "Epoch [10/20], Step [100/200], Loss: 0.8592\n",
            "Epoch [10/20], Step [200/200], Loss: 0.6884\n",
            "End of Epoch 10, Current Learning Rate: 0.0017258987520000003\n",
            "Validation Loss: 0.8288, Accuracy: 70.39%\n",
            "Epoch [11/20], Step [100/200], Loss: 0.7407\n",
            "Epoch [11/20], Step [200/200], Loss: 0.7319\n",
            "End of Epoch 11, Current Learning Rate: 0.0013807190016000004\n",
            "Validation Loss: 0.8320, Accuracy: 70.71%\n",
            "Epoch [12/20], Step [100/200], Loss: 0.6561\n",
            "Epoch [12/20], Step [200/200], Loss: 0.7234\n",
            "End of Epoch 12, Current Learning Rate: 0.0011045752012800003\n",
            "Validation Loss: 0.7877, Accuracy: 71.63%\n",
            "Epoch [13/20], Step [100/200], Loss: 0.7024\n",
            "Epoch [13/20], Step [200/200], Loss: 0.6554\n",
            "End of Epoch 13, Current Learning Rate: 0.0008836601610240002\n",
            "Validation Loss: 0.7877, Accuracy: 72.26%\n",
            "Epoch [14/20], Step [100/200], Loss: 0.7557\n",
            "Epoch [14/20], Step [200/200], Loss: 0.6184\n",
            "End of Epoch 14, Current Learning Rate: 0.0007069281288192002\n",
            "Validation Loss: 0.7688, Accuracy: 72.88%\n",
            "Epoch [15/20], Step [100/200], Loss: 0.6189\n",
            "Epoch [15/20], Step [200/200], Loss: 0.5149\n",
            "End of Epoch 15, Current Learning Rate: 0.0005655425030553602\n",
            "Validation Loss: 0.7916, Accuracy: 72.40%\n",
            "Epoch [16/20], Step [100/200], Loss: 0.5473\n",
            "Epoch [16/20], Step [200/200], Loss: 0.6471\n",
            "End of Epoch 16, Current Learning Rate: 0.00042415687729152016\n",
            "Validation Loss: 0.7558, Accuracy: 73.37%\n",
            "Epoch [17/20], Step [100/200], Loss: 0.5319\n",
            "Epoch [17/20], Step [200/200], Loss: 0.5504\n",
            "End of Epoch 17, Current Learning Rate: 0.0003181176579686401\n",
            "Validation Loss: 0.7839, Accuracy: 72.11%\n",
            "Epoch [18/20], Step [100/200], Loss: 0.4680\n",
            "Epoch [18/20], Step [200/200], Loss: 0.4828\n",
            "End of Epoch 18, Current Learning Rate: 0.00023858824347648008\n",
            "Validation Loss: 0.7518, Accuracy: 73.58%\n",
            "Epoch [19/20], Step [100/200], Loss: 0.5346\n",
            "Epoch [19/20], Step [200/200], Loss: 0.5506\n",
            "End of Epoch 19, Current Learning Rate: 0.00017894118260736007\n",
            "Validation Loss: 0.7432, Accuracy: 73.72%\n",
            "Epoch [20/20], Step [100/200], Loss: 0.5488\n",
            "Epoch [20/20], Step [200/200], Loss: 0.4668\n",
            "End of Epoch 20, Current Learning Rate: 0.00013420588695552005\n",
            "Validation Loss: 0.7442, Accuracy: 73.92%\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 200\n",
        "learning_rate_1 = .01\n",
        "learning_rate_2 = .001\n",
        "num_epochs = 20\n",
        "\n",
        "#initialize dataLoader Objects\n",
        "train_loader_norm = torch.utils.data.DataLoader(train_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "test_loader_norm = torch.utils.data.DataLoader(test_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "val_loader_norm = torch.utils.data.DataLoader(val_data_norm,batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n",
        "#initialize and train model\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "model.train_model(num_epochs, train_loader_norm,val_loader_norm, learning_rate_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 73.85%\n"
          ]
        }
      ],
      "source": [
        "#test model\n",
        "model.test_model(test_loader_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "uVGXIq-D-Jmu",
        "outputId": "db4e3685-e6b4-4841-9bbb-cde015963d4c"
      },
      "outputs": [],
      "source": [
        "# Save the model checkpoint\n",
        "model_path = './MNIST_CNN.pth'\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
